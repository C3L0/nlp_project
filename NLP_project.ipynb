{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "WcIrPuElEmAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**NLP Project**\n",
        "##Project made by:\n",
        "-  Nicolas Laine\n",
        "-  Paul Rouxel\n",
        "-  Quentin Richard\n",
        "-  Barnabé Naturel\n",
        "-  Victor Jouet\n",
        "-  Antoine Lopez\n",
        "\n",
        "**ING5 grp2 Data&IA**\n"
      ],
      "metadata": {
        "id": "1P7oZRhS8kCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sport Orientation with NLP & Skill Analysis\n",
        "\n",
        "This project aims to recommend the best sports for a user based on their answers to a form.\n",
        "\n",
        "The form collects:\n",
        "- Open-ended questions\n",
        "- Likert-scale questions\n",
        "- Numeric questions\n",
        "- MCQs or checkboxes\n",
        "\n",
        "We combine semantic analysis (for open questions) and numeric analysis (for structured answers)\n",
        "The main idea of our code is to produce a **skill vector**(that describe the user). Then we compare it to **sports skill vectors**(pre-made and saved in a .json file) to suggest the best sports.\n"
      ],
      "metadata": {
        "id": "oOEpr1-L-zlc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "898986a6",
        "outputId": "71bd4a8f-49a7-49b6-cfa4-1c4337732372"
      },
      "source": [
        "display(Image(filename='NLP_project_architecture.png', width=1080))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'NLP_project_architecture.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2587204657.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NLP_project_architecture.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NLP_project_architecture.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Analystics\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eKs_PUQ6Gn-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The Goal\n",
        "The system builds a user skill vector. It's the numerical representation of how strong the user is in each skill *(e.g., strength, agility, teamwork, etc.)*.\n",
        "```\n",
        "user_vector = [s1, s2, ...,sn]\n",
        "```\n",
        "\n",
        "Each component *si* represents the user’s estimated level in skill i, derived from both, semantic and numeric analysis.\n",
        "The vectorization process homogenizes multi-format input data, converting diverse user inputs into a single, comparable numeric representation.\n",
        "\n",
        "\n",
        "Similarly, each sport is also represented by a skill requirement vector\n",
        "```\n",
        "sport_vector = [v1, v2, ...,vn]\n",
        "```\n",
        "That indicates how important skill i is for that sport."
      ],
      "metadata": {
        "id": "dsNNXvuiJA8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How the user_vector is build\n",
        "It’s the combination of semantic Analysis from the open-ended answers and numeric analysis from the other format of answer."
      ],
      "metadata": {
        "id": "Xfy6VkeMJB3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Semantic analysis\n",
        "The user writes something like:\n",
        "-  “I like endurance sports and enjoy working in a team.”\n",
        "\n",
        "Each sentence is turned into an embedding (a numerical vector) using SBERT.Then, we compare this sentence vector with each skill embedding (computed once from skill.json). The higher the cosine similarity is the more this sentence relates to that skill."
      ],
      "metadata": {
        "id": "1fnzMmTpL1IF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skills = [\"strength\", \"endurance\", \"teamwork\", \"precision\"]\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "sports = {\n",
        "    \"football\": {\"strength\": 0.8, \"endurance\": 0.9, \"teamwork\": 1.0, \"precision\": 0.6},\n",
        "    \"tennis\": {\"strength\": 0.6, \"endurance\": 0.7, \"teamwork\": 0.4, \"precision\": 0.9},\n",
        "}\n",
        "\n",
        "answer = \"I like working in teams and running long distances.\"\n",
        "\n",
        "# Embeddings\n",
        "# Encode the skill names into numerical vectors\n",
        "skill_embeddings = model.encode(skills, normalize_embeddings=True)\n",
        "# Encode the user's answer into a numerical vector\n",
        "answer_emb = model.encode(answer, normalize_embeddings=True)\n",
        "\n",
        "# Calculate the cosine similarity between the answer embedding and each skill embedding\n",
        "# Cosine similarity measures the angle between two vectors, indicating how similar they are in direction.\n",
        "# A higher cosine similarity means the vectors are more similar.\n",
        "similarities = util.cos_sim(answer_emb, skill_embeddings)[0].cpu().numpy()\n",
        "\n",
        "# Build normalized user vector\n",
        "user_vector = {skill: float(sim) for skill, sim in zip(skills, similarities)}\n",
        "print(user_vector)"
      ],
      "metadata": {
        "id": "8zHj19abL0yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Numeric analysis\n",
        "The numeric anaysis got applicated on the MCQ, Likert, Checkboxes question types.\n",
        "For Likert and checkbox questions, you already know which skill each one measures.\n",
        "```\n",
        "{\n",
        "  \"q3\": {\n",
        "    \"text\": \"How comfortable are you working in a team?\",\n",
        "    \"type\": \"likert\",\n",
        "    \"skill\": \"teamwork\",\n",
        "    \"scale\": {\"min\": 1, \"max\": 10, \"default\": 5}\n",
        "  }\n",
        "}\n",
        "```\n",
        "Then, the analyzer collects all numeric answers into a similar vector:\n"
      ],
      "metadata": {
        "id": "dlRITF6kOgFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# maybe make a code to illustrate"
      ],
      "metadata": {
        "id": "-gFEoRQpPhbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Combining the two\n",
        "Once both semantic and numeric skill profiles are computed, you merge them:<br>\n",
        "`final_scores[skill] = (0.6 * semantic_score + 0.4 * numeric_score)`\n",
        "\n",
        "\n",
        "So the final user skill vector reflects both:\n",
        "- what the user says (semantic meaning), and\n",
        "- what the user rates themselves as (numeric)."
      ],
      "metadata": {
        "id": "nJZnMgyUPhtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Normalization\n",
        "To make all scores comparable across users:\n",
        "`final_profile = SkillAnalyzer.normalize_by_l2(final_scores)`<br>\n",
        "This scales the vector to unit length:<br>\n",
        "X_norm = X / |X|^2<br>\n",
        "\n",
        "It ensures that absolute scale doesn’t matter and only relative strengths between skills matters."
      ],
      "metadata": {
        "id": "i6D0yDHGQRVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#need to do more here\n",
        "def normalize_by_l2(vec):\n",
        "    norm = np.sqrt(sum(v**2 for v in vec.values()))\n",
        "    return {k: v / norm for k, v in vec.items()} if norm else vec"
      ],
      "metadata": {
        "id": "LpH8EYWlRfP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sport Recommender"
      ],
      "metadata": {
        "id": "CrJme_wSSq37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **SportRecommender** compares the user's skill profile to every sport's skill profile using cosine similarity.<br>\n",
        "Each sport is represented as a vector of skill coefficients.<br>\n",
        "The closer the cosine similarity is to 1, the more the two profiles are aligned.<br>\n",
        "The system then returns the top sports with the highest similarity scores."
      ],
      "metadata": {
        "id": "ob4cttf6Sa2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(u, v):\n",
        "    u_vec = np.array(list(u.values()))\n",
        "    v_vec = np.array(list(v.values()))\n",
        "    return np.dot(u_vec, v_vec) / (np.linalg.norm(u_vec) * np.linalg.norm(v_vec))\n",
        "\n",
        "for sport, vec in sports.items():\n",
        "    score = cosine_similarity(user_vector, vec)\n",
        "    print(f\"{sport}: {score:.3f}\")"
      ],
      "metadata": {
        "id": "CkfiYq8rS18p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sources:\n",
        "Architecture schema made on mermaids<br>\n",
        "Model : https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2<br>"
      ],
      "metadata": {
        "id": "_8NFcXE7Nwdo"
      }
    }
  ]
}